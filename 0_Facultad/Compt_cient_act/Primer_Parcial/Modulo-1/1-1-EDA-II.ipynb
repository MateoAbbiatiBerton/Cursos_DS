{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el presente *notebook* se continua trabajando en el análisis de datos. Se traerán conceptos propios de la materia Estadística I y II (FCE-UBA).\n",
    "\n",
    "**Temas:**\n",
    "* Introducción a nueva librería: `scipy`\n",
    "* Relaciones entre variables\n",
    "    * Correlación lineal - Gráficos\n",
    "    * Relaciones no lineales\n",
    "    * Relaciones entre variables categóricas\n",
    "* Análisis de distribuciones\n",
    "    * Gráficamente\n",
    "    * Comparacion de medias y desvios\n",
    "    * Tests de media (T-test) y varianza (Test de Levene y Test de Barlett)\n",
    "    * Test U de Mann-Whitney y  Test de Kolmogorov-Smirnov\n",
    "    * QQ-Plots\n",
    "    \n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Relaciones entre Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Correlación\n",
    "\n",
    "Para el cálculo de la Correlacón entre variables de un dataset podemos recurrir a 3 diferentes librerías:\n",
    "* Pandas\n",
    "* NumPy\n",
    "* Scipy (esta librería está enfocada en temas de Estadística y Probabilidad - [Documentación Oficial](https://scipy.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.linalg import cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "corr_mat= np.array([[1.0, 0.6, 0.3, 0.4],\n",
    "                    [0.6, 1.0, 0.5, 0.8],\n",
    "                    [0.3, 0.5, 1.0, 0.2],\n",
    "                    [0.4, 0.8, 0.2, 1.0]])\n",
    "\n",
    "\n",
    "# Matriz de Descomposición de Cholesky\n",
    "upper_chol = cholesky(corr_mat)\n",
    "\n",
    "rnd = rng.normal(0.0, 1.0, size=(10000, 4))\n",
    "\n",
    "data = rnd @ upper_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['Columna_1', 'Columna_2', 'Columna_3', 'Columna_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez generado el df, se procede a calcular la correlación entre todas las variables disponibles\n",
    "\n",
    "* **Pandas**\n",
    "\n",
    "```python\n",
    "df.corr() --> se puede elegir entre uno de los tres métodos de cómputo existentes: 'pearson', 'kendall', 'spearman'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También es posible calcularlo solamente para cierto subconjunto de columnas\n",
    "\n",
    "df[['Columna_1', 'Columna_3', 'Columna_4']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NumPy\n",
    "\n",
    "```python\n",
    "np.corrcoef(x, y) --> donde 'x' e 'y' son vectores de datos. No se puede calcular para todo el df a la vez.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Columna_1']\n",
    "y = df['Columna_3']\n",
    "\n",
    "np.corrcoef(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scipy\n",
    "\n",
    "```python\n",
    "# Pearson's r\n",
    "scipy.stats.pearsonr(x, y)[0]   \n",
    "\n",
    "# Spearman's rho\n",
    "scipy.stats.spearmanr(x, y)[0]  \n",
    "\n",
    "# Kendall's tau\n",
    "scipy.stats.kendalltau(x, y)[0] \n",
    "```\n",
    "Se está tomando solo el primer elemento del cálculo ya que el segundo elemento de este es el 'p-value'.\n",
    "\n",
    "Scipy devuelve:\n",
    "1. el coeficiente de correlación\n",
    "2. p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's r\n",
    "print('Coeficiente de correlación de Pearson:', stats.pearsonr(x, y)[0])\n",
    "\n",
    "# Spearman's rho\n",
    "print('Coeficiente de correlación de Spearman:', stats.spearmanr(x, y)[0])\n",
    "\n",
    "# Kendall's tau\n",
    "print('Coeficiente de correlación de Kendall:', stats.kendalltau(x, y)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una forma efectiva para analizar esta métrica es mediante una **matriz de correlación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando Seaborn\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "plt.title('Matriz de Correlación')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando Matplotlib \n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.matshow(correlation_matrix, cmap='coolwarm')\n",
    "\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation='vertical')\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.title('Matriz de Correlación')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otra forma de visualizarlo es mediante gráficos de dispersión (*scatter plots*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20, 6))\n",
    "\n",
    "sns.scatterplot(x=df['Columna_1'], y=df['Columna_2'], ax=ax[0])\n",
    "sns.scatterplot(x=df['Columna_2'], y=df['Columna_4'], ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Scatter Columnas 1 y 2')\n",
    "ax[1].set_title('Scatter Columnas 2 y 4')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Relaciones no lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = rng.uniform(25, 80, size=10_000) * np.clip(rng.exponential(1, size = 10_000), 1, 3)\n",
    "col_2 = col_1 * 1.25 + rng.normal(4, 8, size = 10_000) * 2\n",
    "col_3 = rng.uniform(2, 4, size=10_000) * col_1**2 + rng.uniform(1, 2.5, size=10_000) * col_1 + rng.normal(2, 5, size = 10_000)\n",
    "col_4 = 1 / (rng.uniform(2, 4, size=10_000) * col_1**2 + rng.uniform(1, 2.5, size=10_000) * col_1 + rng.normal(2, 5, size = 10_000))\n",
    "df = pd.DataFrame(data = {'Columna_1': col_1, 'Columna_2': col_2, 'Columna_3': col_3, 'Columna_4': col_4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "plt.title('Matriz de Correlación')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20, 6))\n",
    "\n",
    "sns.scatterplot(x=df['Columna_1'], y=df['Columna_2'], ax=ax[0])\n",
    "sns.scatterplot(x=df['Columna_1'], y=df['Columna_3'], ax=ax[1])\n",
    "sns.scatterplot(x=df['Columna_1'], y=df['Columna_4'], ax=ax[2])\n",
    "\n",
    "ax[0].set_title('Scatter Columnas 1 y 2')\n",
    "ax[1].set_title('Scatter Columnas 1 y 3')\n",
    "ax[2].set_title('Scatter Columnas 1 y 4')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Correlación entre variables categóricas\n",
    "\n",
    "Para analizar la correlacón entre las variables categóricas se recurrirá al uso del Test Chi-Cuadrado, donde\n",
    "\n",
    "* $H_0$: no existe relación entre la variable $i$ y la variable $j$\n",
    "* $H_1$: existe relación entre la variable $i$ y la variable $j$ .\n",
    "\n",
    "El test se aplica sobre una tabla de contingencia. Por ende, **es necesario tener una tabla de contingencia para poder realizar el test**.\n",
    "\n",
    "| Columna 1 / Columna 2  | **Y** | **Z** |\n",
    "|---|---------|---------|\n",
    "| **A** |   A Y |   A Z |\n",
    "| **B** |   B Y |   B Z |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para ello importamos la siguiente función\n",
    "\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1\n",
    "tabla = np.array([[528, 472],\n",
    "                  [723, 287]])\n",
    "\n",
    "res = chi2_contingency(tabla)\n",
    "\n",
    "print(f'Valor del test: {res.statistic}', f'p-value: {res.pvalue}', sep='\\n')\n",
    "\n",
    "print('Se rechaza la hipótesis nula. Existe relación entre las dos variables.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2\n",
    "tabla = np.array([[25, 390],\n",
    "                  [2034, 1652]])\n",
    "\n",
    "res = chi2_contingency(tabla)\n",
    "\n",
    "print(f'Valor del test: {res.statistic}', f'p-value: {res.pvalue}', sep='\\n')\n",
    "\n",
    "print('Se rechaza la hipótesis nula. Existe relación entre las dos variables.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3\n",
    "tabla = np.array([[1000, 1023],\n",
    "                  [900, 876]])\n",
    "\n",
    "res = chi2_contingency(tabla)\n",
    "\n",
    "print(f'Valor del test: {res.statistic}', f'p-value: {res.pvalue}', sep='\\n')\n",
    "\n",
    "print('No se rechaza la hipótesis nula. NO existe relación entre las dos variables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para generar la tabla de contingencia dado un conjunto de datos se recurre a la función `crosstab` de `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ESTUDIO': ['estudio', 'no estudio', 'estudio','estudio', 'no estudio',\n",
    "                    'no estudio', 'estudio','estudio','no estudio', 'estudio',\n",
    "                    'no estudio', 'estudio','estudio', 'no estudio', 'estudio',\n",
    "                    'estudio','estudio','no estudio','estudio','estudio'],\n",
    "        'APROBADO':  ['si','no','si','si','no',\n",
    "                      'si','si','no','no','si',\n",
    "                      'no','si','si','si','no',\n",
    "                      'si','si','no','si','si'] \n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genero la tabla de contingencia\n",
    "tabla = pd.crosstab(index=df['ESTUDIO'], columns=df['APROBADO'])\n",
    "\n",
    "display(tabla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chi2_contingency(tabla)\n",
    "\n",
    "print(f'Valor del test: {res.statistic}', f'p-value: {res.pvalue}', sep='\\n')\n",
    "\n",
    "print('Se rechaza la hipótesis nula. Existe relación entre las dos variables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Análisis de distribuciones\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar las muestras de datos para analizar\n",
    "dist_A = rng.normal(5,3, size=10_000) # --> distribución Normal con mu=5 y sigma=3\n",
    "dist_B = rng.normal(5.2,2.8, size=10_000) # --> distribución Normal con mu=5.2 y sigma=2.8\n",
    "dist_C = rng.normal(8,3, size=10_000) # --> distribución Normal con mu=8 y sigma=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primero se puede realizar un análisis visual mediante gráficos de las distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "\n",
    "# Upper plot\n",
    "f_ax1 = fig.add_subplot(gs[0, :])\n",
    "\n",
    "sn.kdeplot(dist_A, color='#1f5ab8', ax=f_ax1, label='Dist A')\n",
    "sn.kdeplot(dist_B, color='#db46e3', ax=f_ax1, label='Dist B')\n",
    "sn.kdeplot(dist_C, color= '#e8d60c', ax=f_ax1, label='Dist C')\n",
    "\n",
    "f_ax1.set_title('PDF')\n",
    "f_ax1.legend()\n",
    "\n",
    "#################################\n",
    "# Subplot 1\n",
    "#################################\n",
    "f_ax2 = fig.add_subplot(gs[1, 0])\n",
    "tf_ax2 = f_ax2.twinx()\n",
    "\n",
    "sn.kdeplot(dist_A, color='#1f5ab8', ax=f_ax2, label='PDF')\n",
    "sn.ecdfplot(dist_A, color='#1f5ab8', ax=tf_ax2, linestyle='--', label='ECDF')\n",
    "\n",
    "f_ax2.set_title('Dist A')\n",
    "\n",
    "handles, labels = f_ax2.get_legend_handles_labels()\n",
    "handles2, labels2 = tf_ax2.get_legend_handles_labels()\n",
    "f_ax2.legend(handles + handles2, labels + labels2, loc='upper right')\n",
    "\n",
    "#################################\n",
    "# Subplot 2\n",
    "#################################\n",
    "f_ax3 = fig.add_subplot(gs[1, 1])\n",
    "tf_ax3 = f_ax3.twinx()\n",
    "\n",
    "sn.kdeplot(dist_B, color='#db46e3', ax=f_ax3, label='PDF')\n",
    "sn.ecdfplot(dist_B, color='#db46e3', ax=tf_ax3, linestyle='--', label='ECDF')\n",
    "\n",
    "f_ax3.set_title('Dist B')\n",
    "\n",
    "handles, labels = f_ax3.get_legend_handles_labels()\n",
    "handles2, labels2 = tf_ax3.get_legend_handles_labels()\n",
    "f_ax3.legend(handles + handles2, labels + labels2, loc='upper right')\n",
    "\n",
    "#################################\n",
    "# Subplot 3\n",
    "#################################\n",
    "f_ax4 = fig.add_subplot(gs[1, 2])\n",
    "tf_ax4 = f_ax4.twinx()\n",
    "\n",
    "sn.kdeplot(dist_C, color='#e8d60c', ax=f_ax4, label='PDF')\n",
    "sn.ecdfplot(dist_C, color='#e8d60c', ax=tf_ax4, linestyle='--', label='ECDF')\n",
    "\n",
    "f_ax4.set_title('Dist C')\n",
    "\n",
    "handles, labels = f_ax4.get_legend_handles_labels()\n",
    "handles2, labels2 = tf_ax4.get_legend_handles_labels()\n",
    "f_ax4.legend(handles + handles2, labels + labels2, loc='upper right')\n",
    "\n",
    "#################################\n",
    "\n",
    "fig.suptitle('Análisis de las distribuciones')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otra forma posible de comparar las distribuciones es mediante sus medidas estadísticas de posición y dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in zip(['A', 'B', 'C'], [dist_A, dist_B, dist_C]):\n",
    "    print('La media de la distribución {} es {} y varianza es {}.'.format(d[0], np.mean(d[1]), np.var(d[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por medio de tests estadísticos podemos determinar si las muestras provienen de la misma distribución: *Test U de Mann-Whitney*.\n",
    "    * $H_0$: las muestras provienen de la misma distribución.\n",
    "    * $H_1$: las muestras no provienen de la misma distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, pvalue = mannwhitneyu(dist_A, dist_B)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = mannwhitneyu(dist_A, dist_C)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Es posible testear si la media de ambas muestras en la misma por medio del **T-test**.\n",
    "  * $H_0$: las muestras provienen de distribuciones con la misma media.\n",
    "  * $H_1$: las muestras no provienen de distribuciones con la misma media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = stats.ttest_ind(dist_A, dist_C,equal_var=True)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de A y C tiene sentido que la $H_0$ sea rechazada ya que las distribuciones poseen media 5 y 8, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = stats.ttest_ind(dist_A, dist_B)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las distribuciones A y B (cuyas medias poblacionales son 5 y 5.2) vemos que, a pesar de la pequeña diferencia de medias, el test rechaza la $H_1$ de forma marcada.\n",
    "\n",
    "Ahora se toma una sub-muestra de las muestras anteriores y se analiza los resultados del test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [20, 50, 100, 500, 1000, 2500, 5000]\n",
    "alpha = 0.05\n",
    "\n",
    "for size in sample_sizes: \n",
    "\n",
    "    sample_A = rng.choice(a=dist_A,replace=False,size=size)\n",
    "    sample_B = rng.choice(a=dist_B,replace=False,size=size)\n",
    "    \n",
    "    stat, pvalue = stats.ttest_ind(sample_A, # --> muestra dist A\n",
    "                                   sample_B # --> muestra dist B\n",
    "                                  )\n",
    "    \n",
    "    print('-'*30, 'Tamaño de la muestra: {}'.format(size),sep='\\n')\n",
    "    print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "    print('Media A: {:.4f} \\t Media B: {:.4f}'.format(np.mean(sample_A), np.mean(sample_B)))\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print('No se rechaza la hipótesis nula.')\n",
    "    else:\n",
    "        print('Se rechaza la hipótesis nula.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados permite observar que, a medida que aumenta el tamaño de la muestra, el valor de *p-value* decrece y el valor de estadístico aumenta. Esto se debe a que el tamaño de la muestra que se ingesta en el test posee un efecto sumamente importante en los resultados del mismo.\n",
    "\n",
    "A mayor tamaño de muestra, más similar deberán ser las medias para que no se rechace la $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Es posible testear si la varianza de ambas muestras en la misma por medio del **Test de Barlett**.\n",
    "  * $H_0$: las muestras provienen de distribuciones con la misma varianza.\n",
    "  * $H_1$: las muestras no provienen de distribuciones con la misma varianza.\n",
    "\n",
    "(*Para los casos donde las muestras difieren significativmante de una distribución normal el **Test de Levene** es más robusto.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = stats.bartlett(dist_A, dist_B)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = stats.bartlett(dist_A, dist_C)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otro test que permite analizar la diferencia entre distribuciones es el de **Kolmogorov-Smirnov** (o **Test KS**):\n",
    "  * $H_0$: las muestras provienen de la misma distribución.\n",
    "  * $H_1$: las muestras no provienen de la misma distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = stats.ks_2samp(dist_A, dist_B)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue = stats.ks_2samp(dist_A, dist_C)\n",
    "\n",
    "print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if pvalue > alpha:\n",
    "    print('No se rechaza la hipótesis nula.')\n",
    "else:\n",
    "    print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de los tests se puede contrastar gráficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(18, 6))\n",
    "\n",
    "ax1, ax2 = ax.flatten()\n",
    "\n",
    "###############################\n",
    "# Subplot izquierda\n",
    "###############################\n",
    "\n",
    "sn.ecdfplot(dist_A, color='#1f5ab8', label='Dist A', ax=ax1) \n",
    "sn.ecdfplot(dist_B, color='#db46e3', label='Dist B', ax=ax1)\n",
    "\n",
    "ax1.set_title('CDF - Dist A y B')\n",
    "ax1.set_ylim((-0.025, 1.025))\n",
    "ax1.set_xlabel('Valores')\n",
    "ax1.set_ylabel('Probabilidad')\n",
    "ax1.legend()\n",
    "\n",
    "###############################\n",
    "# Subplot derecha\n",
    "###############################\n",
    "\n",
    "sn.ecdfplot(dist_A, color='#1f5ab8', label='Dist A', ax=ax2) \n",
    "sn.ecdfplot(dist_C, color='#e8d60c', label='Dist C', ax=ax2)\n",
    "\n",
    "ax2.set_title('CDF - Dist A y C')\n",
    "ax2.set_ylim((-0.025, 1.025))\n",
    "ax2.set_xlabel('Valores')\n",
    "ax2.set_ylabel('Probabilidad')\n",
    "ax2.legend()\n",
    "\n",
    "###############################\n",
    "# Figura\n",
    "###############################\n",
    "plt.suptitle('Funciones de Densidad/Probilidad Acumulada')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale destacar que, al igual que los tests anteriores, el tamaño de la muestra influye en el output del test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [20, 50, 100, 500, 1000, 2500, 5000]\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "for size in sample_sizes: \n",
    "\n",
    "    sample_A = rng.choice(a=dist_A,replace=False,size=size)\n",
    "    sample_B = rng.choice(a=dist_B,replace=False,size=size)\n",
    "    \n",
    "    stat, pvalue = stats.ks_2samp(sample_A, # --> muestra dist A\n",
    "                                   sample_B # --> muestra dist B\n",
    "                                  )\n",
    "    \n",
    "    print('-'*30, 'Tamaño de la muestra: {}'.format(size),sep='\\n')\n",
    "    print('Valor del test={:.3f}, p-value={:.5f}'.format(stat, pvalue))\n",
    "\n",
    "    if pvalue > alpha:\n",
    "        print('No se rechaza la hipótesis nula.')\n",
    "    else:\n",
    "        print('Se rechaza la hipótesis nula.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por medio del gráfico QQ (o QQ-Plot) podemos ver analizar las distribuciones en todo su dominio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=np.linspace(0, 100, 100)\n",
    "\n",
    "qa = np.percentile(dist_A, q=q)\n",
    "qb = np.percentile(dist_B, q=q)\n",
    "qc = np.percentile(dist_C, q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(18, 6))\n",
    "\n",
    "ax1, ax2 = ax.flatten()\n",
    "\n",
    "###############################\n",
    "# Subplot izquierda\n",
    "###############################\n",
    "\n",
    "# gráfico de puntos (QQ Plot)\n",
    "ax1.scatter(qa,qb,c='#1e74c9', label='Percentiles')\n",
    "\n",
    "# línea diagonal\n",
    "x1= min(min(qa), min(qb))\n",
    "x2= max(max(qa), max(qb))\n",
    "y1=x1\n",
    "y2=x2\n",
    "\n",
    "ax1.plot((x1, x2), (y1, y2), linestyle='--', alpha = 0.85, color='#202326', label='Línea de coincidencia exacta')\n",
    "\n",
    "ax1.set_xlabel('Valor de Percentiles - Dist A')\n",
    "ax1.set_ylabel('Valor de Percentiles - Dist B')\n",
    "\n",
    "ax1.legend()\n",
    "ax1.set_title('QQ Plot (A y B)')\n",
    "\n",
    "###############################\n",
    "# Subplot derecha\n",
    "###############################\n",
    "\n",
    "# gráfico de puntos (QQ Plot)\n",
    "ax2.scatter(qa,qc,c='#33d654', label='Percentiles')\n",
    "\n",
    "# línea diagonal\n",
    "x1= min(min(qa), min(qc))\n",
    "x2= max(max(qa), max(qc))\n",
    "y1=x1\n",
    "y2=x2\n",
    "\n",
    "ax2.plot((x1, x2), (y1, y2), linestyle='--', alpha = 0.85, color='#202326', label='Línea de coincidencia exacta')\n",
    "\n",
    "ax2.set_xlabel('Valor de Percentiles - Dist A')\n",
    "ax2.set_ylabel('Valor de Percentiles - Dist C')\n",
    "\n",
    "ax2.legend()\n",
    "ax2.set_title('QQ Plot (A y C)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
